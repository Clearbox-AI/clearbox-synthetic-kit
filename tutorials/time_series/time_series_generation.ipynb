{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series synthetic data \n",
    "### A generation and evaluation example with **Clearbox Engine**\n",
    "\n",
    "This notebook walks you through the time-series synthetic data generation and evaluation process with **Clearbox Engine**.\n",
    "\n",
    "You can run this notebook on Google Colab or on your local machine.<br> \n",
    "In the second case, we highly recommend to create a dedicated virtual environment.\n",
    "\n",
    "<div class=\"alert alert-secondary\">\n",
    "To run this notebook, make sure you change the runtime to <strong>GPU</strong><br>\n",
    "<hr>\n",
    "<strong>Runtime</strong> --> <strong>Change Runtime Type</strong> <br>\n",
    "and set <strong>Hardware Accelerator</strong> to \"<strong>GPU</strong>\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library and its dependencies\n",
    "\n",
    "%pip install clearbox-synthetic-kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from clearbox_synthetic.utils import Dataset\n",
    "\n",
    "#from clearbox_synthetic.generation import TimeSeriesEngine\n",
    "from clearbox_preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = Dataset.from_csv('./data/daily_delhi_climate/DailyDelhiClimateTrain.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Datasets are pre-processd with the **Preprocessor** class, which prepares data for the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a time index column with year and month, as \"yyyymm\"\n",
    "train_dataset.data['id'] =train_dataset.data['date'].apply(lambda x: ''.join(x.split('-')[0:2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synhetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters (encoder): 26996\n",
      "Number of parameters (decoder): 25200\n"
     ]
    }
   ],
   "source": [
    "# Initializing the time series generator\n",
    "\n",
    "engine = TimeSeriesEngine(\n",
    "    dataset = train_dataset,\n",
    "    layers_size=[40],\n",
    "    time_id='id',\n",
    ")\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def count_parameters(params_dict):\n",
    "    total_count = 0\n",
    "    for key, value in params_dict.items():\n",
    "        if isinstance(value, dict):  # If the value is another dictionary, recurse\n",
    "            total_count += count_parameters(value)\n",
    "        elif isinstance(value, jnp.ndarray):  # If the value is an array, count parameters\n",
    "            total_count += value.size\n",
    "    return total_count\n",
    "\n",
    "# Count the total number of parameters\n",
    "\n",
    "total_params = count_parameters(engine.params['encoder'])\n",
    "print(\"Number of parameters (encoder):\", total_params)\n",
    "total_params = count_parameters(engine.params['decoder'])\n",
    "print(\"Number of parameters (decoder):\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-30 18:08:28.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m570\u001b[0m - \u001b[1mPreprocessing training time series\u001b[0m\n",
      "49it [00:00, 1387.73it/s]\n",
      "Engine fitting in progress: 100%|█████████████████████████| 1000/1000 [00:08<00:00, 115.33epoch/s, Train loss=12521.055]\n"
     ]
    }
   ],
   "source": [
    "engine.fit(train_dataset, epochs=1000, learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.generate(train_dataset,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
